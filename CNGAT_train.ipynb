{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "# load dataset\n",
    "testset = np.load('./testset_demo.npz')\n",
    "\n",
    "test_features = torch.from_numpy(testset['F']/100)## normalized dBZ：(lgz)/10\n",
    "test_labels = torch.from_numpy( (np.log10(testset['L']+1)) ) ## transformed precipitation labels：y=lg(y+1)\n",
    "test_mask = torch.from_numpy(testset['M'])\n",
    "del testset\n",
    "gc.collect()\n",
    "\n",
    "num_feats = test_features.shape[2]\n",
    "N_test  = test_features.shape[0]\n",
    "N_val = np.floor(N_test/2)\n",
    "N_val = N_val.astype(np.int32)\n",
    "\n",
    "trainset = np.load('./trainset_demo.npz') \n",
    "train_features = torch.from_numpy(trainset['F']/100)\n",
    "train_labels = torch.from_numpy( (np.log10(trainset['L']+1)) ) \n",
    "train_mask = torch.from_numpy(trainset['M'])\n",
    "\n",
    "N_train  = train_features.shape[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "from dgl import DGLGraph\n",
    "from dgl.data import register_data_args, load_data\n",
    "#from gat import GAT\n",
    "\n",
    "from snat import SNAT\n",
    "from output_layer import  output\n",
    "from utils import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNAT(\n",
      "  (snat_layers): ModuleList(\n",
      "    (0): SNATConv(\n",
      "      (h1): Linear(in_features=1, out_features=16, bias=False)\n",
      "      (h1_rear): Linear(in_features=1, out_features=16, bias=False)\n",
      "      (fc_rear): Linear(in_features=16, out_features=16, bias=False)\n",
      "      (fc): Linear(in_features=16, out_features=16, bias=False)\n",
      "      (feat_drop): Dropout(p=0, inplace=False)\n",
      "      (attn_drop): Dropout(p=0, inplace=False)\n",
      "      (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (1): SNATConv(\n",
      "      (h1): Linear(in_features=16, out_features=16, bias=False)\n",
      "      (h1_rear): Linear(in_features=16, out_features=16, bias=False)\n",
      "      (fc_rear): Linear(in_features=16, out_features=16, bias=False)\n",
      "      (fc): Linear(in_features=16, out_features=16, bias=False)\n",
      "      (feat_drop): Dropout(p=0, inplace=False)\n",
      "      (attn_drop): Dropout(p=0, inplace=False)\n",
      "      (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (2): SNATConv(\n",
      "      (h1): Linear(in_features=16, out_features=16, bias=False)\n",
      "      (h1_rear): Linear(in_features=16, out_features=16, bias=False)\n",
      "      (fc_rear): Linear(in_features=16, out_features=16, bias=False)\n",
      "      (fc): Linear(in_features=16, out_features=16, bias=False)\n",
      "      (feat_drop): Dropout(p=0, inplace=False)\n",
      "      (attn_drop): Dropout(p=0, inplace=False)\n",
      "      (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (3): SNATConv(\n",
      "      (h1): Linear(in_features=16, out_features=16, bias=False)\n",
      "      (h1_rear): Linear(in_features=16, out_features=16, bias=False)\n",
      "      (fc_rear): Linear(in_features=16, out_features=16, bias=False)\n",
      "      (fc): Linear(in_features=16, out_features=16, bias=False)\n",
      "      (feat_drop): Dropout(p=0, inplace=False)\n",
      "      (attn_drop): Dropout(p=0, inplace=False)\n",
      "      (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "    (4): SNATConv(\n",
      "      (h1): Linear(in_features=16, out_features=16, bias=False)\n",
      "      (h1_rear): Linear(in_features=16, out_features=16, bias=False)\n",
      "      (fc_rear): Linear(in_features=16, out_features=64, bias=False)\n",
      "      (fc): Linear(in_features=16, out_features=64, bias=False)\n",
      "      (feat_drop): Dropout(p=0, inplace=False)\n",
      "      (attn_drop): Dropout(p=0, inplace=False)\n",
      "      (leaky_relu): LeakyReLU(negative_slope=0.2)\n",
      "    )\n",
      "  )\n",
      "  (output): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n",
      "Epoch 00000 | Time(s) nan | Loss 0.084841 |val_error315.9041\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch 00001 | Time(s) nan | Loss 0.067905 |val_error326.9004\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch 00002 | Time(s) nan | Loss 0.070123 |val_error320.8525\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch 00003 | Time(s) 1215.4802 | Loss 0.065780 |val_error330.7299\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch 00004 | Time(s) 1216.2010 | Loss 0.065466 |val_error317.8011\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch 00005 | Time(s) 1216.3523 | Loss 0.068159 |val_error353.1780\n",
      "Epoch 00006 | Time(s) 1216.1800 | Loss 0.065778 |val_error307.8295\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch 00007 | Time(s) 1216.3400 | Loss 0.065756 |val_error336.9774\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch 00008 | Time(s) 1216.0995 | Loss 0.066878 |val_error381.2761\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch 00009 | Time(s) 1215.8696 | Loss 0.064670 |val_error410.9336\n",
      "Epoch 00010 | Time(s) 1215.7322 | Loss 0.065231 |val_error298.4152\n",
      "EarlyStopping counter: 1 out of 30\n",
      "Epoch 00011 | Time(s) 1215.6026 | Loss 0.064500 |val_error405.9104\n",
      "EarlyStopping counter: 2 out of 30\n",
      "Epoch 00012 | Time(s) 1215.5228 | Loss 0.067301 |val_error380.1070\n",
      "EarlyStopping counter: 3 out of 30\n",
      "Epoch 00013 | Time(s) 1215.5798 | Loss 0.065958 |val_error357.7811\n",
      "EarlyStopping counter: 4 out of 30\n",
      "Epoch 00014 | Time(s) 1215.6129 | Loss 0.066242 |val_error333.6837\n",
      "EarlyStopping counter: 5 out of 30\n",
      "Epoch 00015 | Time(s) 1215.6297 | Loss 0.065285 |val_error331.4860\n",
      "EarlyStopping counter: 6 out of 30\n",
      "Epoch 00016 | Time(s) 1215.7085 | Loss 0.064338 |val_error376.9098\n",
      "EarlyStopping counter: 7 out of 30\n",
      "Epoch 00017 | Time(s) 1215.6503 | Loss 0.065874 |val_error403.3897\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def mean_square_error(y,labels):\n",
    "    mean_e= torch.sum((y-labels)**2)\n",
    "    n = y.size(0)\n",
    "    return mean_e, n\n",
    "\n",
    "def b_ms_error(y,labels):\n",
    "    s_e= torch.sum(labels*(y-labels)**2)\n",
    "    n = labels.sum()\n",
    "    return s_e, n\n",
    "\n",
    "\n",
    "def evaluate0(model, features, labels, mask, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y = model(features)\n",
    "        y = y[mask]\n",
    "        y = y.flatten(0) \n",
    "        y = 10**y-1\n",
    "        labels = 10**labels-1\n",
    "        return criterion(y, labels[mask])\n",
    "\n",
    "\n",
    "gpu= 0 #gpu device\n",
    "#hyperparameters\n",
    "\n",
    "threhold = 0.4##\n",
    "num_heads=1\n",
    "num_out_heads=1\n",
    "num_layers = 4\n",
    "num_hidden= 16\n",
    "out_dim= 64\n",
    "early_stop= True\n",
    "fastmode= False\n",
    "\n",
    "if gpu < 0:\n",
    "    cuda = False\n",
    "else:\n",
    "    cuda = True\n",
    "    torch.cuda.set_device(gpu)\n",
    "\n",
    "from dgl.data.utils import load_graphs\n",
    "g = load_graphs(\"./Graph.bin\",[0])\n",
    "g = g[0][0]\n",
    "\n",
    "# create model\n",
    "heads = torch.zeros(num_layers+1,dtype=torch.int32)\n",
    "nhidT = torch.zeros(num_layers+1,dtype=torch.int32)\n",
    "heads[0:num_layers]=num_heads\n",
    "heads[-1]=num_out_heads\n",
    "nhidT[0]= 16\n",
    "nhidT[1]=16\n",
    "nhidT[2]=16\n",
    "nhidT[3]=16\n",
    "nhidT[4]=16\n",
    "#nhidT[5]=16\n",
    "#nhidT[6]=16\n",
    "model = SNAT(g,\n",
    "             threhold,\n",
    "            num_layers,\n",
    "            num_feats,\n",
    "            num_hidden,\n",
    "            out_dim,\n",
    "            heads=heads,\n",
    "            num_hiddenT=nhidT,\n",
    "            feat_drop =0,\n",
    "            attn_drop = 0,\n",
    "            negative_slope=0.2,\n",
    "            activation= torch.tanh,  ##每层的激活函数\n",
    "            residual=False)\n",
    "\n",
    "\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "    \n",
    "print(model)\n",
    "if early_stop:\n",
    "    stopper = EarlyStopping(patience=30)\n",
    "\n",
    "loss_fcn = torch.nn.MSELoss(reduction='none')   \n",
    "\n",
    "# use optimizer\n",
    "optimizer1 = torch.optim.Adam(\n",
    "    model.parameters(), lr=1e-4)##不知道对不对\n",
    "#optimizer1 = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "dur = []\n",
    "for epoch in range(200):\n",
    "\n",
    "    val_error=0\n",
    "    loss_m = 0\n",
    "    N_total = 0\n",
    "    if epoch >= 3:\n",
    "        t0 = time.time()\n",
    "    rand_n=torch.randperm(N_train) \n",
    "    batchsize= 1  \n",
    "    nbatches = int(N_train/batchsize/3) #use 1/3 of the training data every epoch\n",
    "    N_nodes_train= 0\n",
    "    for batch in range(nbatches):\n",
    "        N_ba = 0\n",
    "        for n in range(batchsize): \n",
    "            model.train()\n",
    "\n",
    "            # forward\n",
    "            index_n = rand_n[n+batchsize*batch]\n",
    "            H0 = train_features[index_n,:,:]\n",
    "            index_0rd = (H0==0).flatten()\n",
    "            train_labels[index_n,index_0rd]=0##去除异常值\n",
    "            index_2rd = (train_labels[index_n]>2).flatten()\n",
    "            train_mask[index_n,index_2rd]=False ##去除太大的zhi\n",
    "            labels = train_labels[index_n,train_mask[index_n,:]]\n",
    "            if cuda== true:\n",
    "                H0=H0.cuda()\n",
    "                labels = labels.cuda()\n",
    "            N_t = labels.size(0)\n",
    "            y = model(H0) \n",
    "            index_0 = (labels) ==0 ###标签为0的索引\n",
    "            W_nodes = 10**(labels)  ##  weigtht for none zero label: W\n",
    "            W_nodes[index_0]=0.1  ## weight for zero label: W0\n",
    "            loss = loss_fcn( y[train_mask[index_n,:],:].flatten(),\n",
    "                            train_labels[index_n,train_mask[index_n,:]].cuda() )  ###compute the loss for every (labeled) node\n",
    "\n",
    "            loss = loss*W_nodes \n",
    "            loss_w = loss.mean() ## average loss among all nodes\n",
    "            loss_m += loss.sum().item()\n",
    "            loss_w.backward()\n",
    "            N_ba +=N_t\n",
    "        optimizer1.step() \n",
    "        optimizer1.zero_grad()\n",
    "        N_nodes_train += N_ba           \n",
    "    for n in range(N_val):\n",
    "        model.eval()\n",
    "        index_0rd = (test_features[n]==0).flatten()\n",
    "        test_labels[n,index_0rd]=0##去除异常值\n",
    "        mask = (10**test_labels[n]-1)>0\n",
    "        index_2rd = (test_labels[n]>2).flatten()\n",
    "        test_mask[n,index_2rd]=False ##去除太大的zhi\n",
    "        mask = mask&test_mask[n]\n",
    "        \n",
    "        val_error0, N0 = evaluate0(model, test_features[n,:,:].cuda(), test_labels[n,:].cuda(),mask, b_ms_error)#\n",
    "        val_error += val_error0\n",
    "        N_total += N0\n",
    "        \n",
    "    val_error/=N_total\n",
    "    if early_stop: \n",
    "        if stopper.step(-val_error, model, 'CNGAT_16*4_64.pt'):   \n",
    "            break\n",
    "    loss_m = loss_m/N_nodes_train\n",
    "    if epoch >= 3:\n",
    "        dur.append(time.time() - t0)\n",
    "    print(\"Epoch {:05d} | Time(s) {:.4f} | Loss {:.6f} |val_error{:.4f}\".\n",
    "              format(epoch, np.mean(dur), loss_m, val_error))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PPXXpytorch] *",
   "language": "python",
   "name": "conda-env-PPXXpytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
