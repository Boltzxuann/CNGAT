{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "# load dataset\n",
    "testset = np.load('./testset_demo.npz')\n",
    "\n",
    "test_features = torch.from_numpy(testset['F']/100)## normalized dBZ：(lgz)/10\n",
    "test_labels = torch.from_numpy( (np.log10(testset['L']+1)) ) ## transformed precipitation labels：y=lg(y+1)\n",
    "test_mask = torch.from_numpy(testset['M'])\n",
    "del testset\n",
    "\n",
    "num_feats = test_features.shape[2]\n",
    "N_test  = test_features.shape[0]\n",
    "N_val = np.floor(N_test/2)\n",
    "N_val = N_val.astype(np.int32)\n",
    "\n",
    "trainset = np.load('./trainset_demo.npz') \n",
    "train_features = torch.from_numpy(trainset['F']/100)\n",
    "train_labels = torch.from_numpy( (np.log10(trainset['L']+1)) ) \n",
    "train_mask = torch.from_numpy(trainset['M'])\n",
    "\n",
    "N_train  = train_features.shape[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "from dgl import DGLGraph\n",
    "from dgl.data import register_data_args, load_data\n",
    "#from gat import GAT\n",
    "\n",
    "from snat import SNAT\n",
    "from output_layer import  output\n",
    "from utils import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def mean_square_error(y,labels):\n",
    "    mean_e= torch.sum((y-labels)**2)\n",
    "    n = y.size(0)\n",
    "    return mean_e, n\n",
    "\n",
    "def b_ms_error(y,labels):\n",
    "    s_e= torch.sum(labels*(y-labels)**2)\n",
    "    n = labels.sum()\n",
    "    return s_e, n\n",
    "\n",
    "\n",
    "def evaluate0(model, features, labels, mask, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y = model(features)\n",
    "        y = y[mask]\n",
    "        y = y.flatten(0) \n",
    "        y = 10**y-1\n",
    "        labels = 10**labels-1\n",
    "        return criterion(y, labels[mask])\n",
    "\n",
    "\n",
    "gpu= 0 #gpu device\n",
    "#hyperparameters\n",
    "\n",
    "threhold = 0.4## boundary for dividing node types\n",
    "num_heads=1\n",
    "num_out_heads=1\n",
    "num_layers = 6\n",
    "num_hidden= 16\n",
    "out_dim= 64\n",
    "early_stop= True\n",
    "fastmode= False\n",
    "\n",
    "if gpu < 0:\n",
    "    cuda = False\n",
    "else:\n",
    "    cuda = True\n",
    "    torch.cuda.set_device(gpu)\n",
    "\n",
    "from dgl.data.utils import load_graphs\n",
    "g = load_graphs(\"./Graph.bin\",[0])\n",
    "g = g[0][0]\n",
    "\n",
    "# create model\n",
    "heads = torch.zeros(num_layers+1,dtype=torch.int32)\n",
    "nhidT = torch.zeros(num_layers+1,dtype=torch.int32)\n",
    "heads[0:num_layers]=num_heads\n",
    "heads[-1]=num_out_heads\n",
    "nhidT[0]= 16\n",
    "nhidT[1]=16\n",
    "nhidT[2]=16\n",
    "nhidT[3]=16\n",
    "nhidT[4]=16\n",
    "nhidT[5]=16\n",
    "nhidT[6]=16\n",
    "model = SNAT(g,\n",
    "             threhold,\n",
    "            num_layers,\n",
    "            num_feats,\n",
    "            num_hidden,\n",
    "            out_dim,\n",
    "            heads=heads,\n",
    "            num_hiddenT=nhidT,\n",
    "            feat_drop =0,\n",
    "            attn_drop = 0,\n",
    "            negative_slope=0.2,\n",
    "            activation= torch.tanh,  ##activation function for intermidiate layers\n",
    "            residual=False)\n",
    "\n",
    "\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "    \n",
    "print(model)\n",
    "if early_stop:\n",
    "    stopper = EarlyStopping(patience=30)\n",
    "\n",
    "loss_fcn = torch.nn.MSELoss(reduction='none')   \n",
    "\n",
    "# use optimizer\n",
    "optimizer1 = torch.optim.Adam(\n",
    "    model.parameters(), lr=1e-4)##不知道对不对\n",
    "#optimizer1 = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "dur = []\n",
    "for epoch in range(200):\n",
    "\n",
    "    val_error=0\n",
    "    loss_m = 0\n",
    "    N_total = 0\n",
    "    if epoch >= 3:\n",
    "        t0 = time.time()\n",
    "    rand_n=torch.randperm(N_train) \n",
    "    batchsize= 1  \n",
    "    nbatches = int(N_train/batchsize/3) #use 1/3 of the training data every epoch\n",
    "    N_nodes_train= 0\n",
    "    for batch in range(nbatches):\n",
    "        N_ba = 0\n",
    "        for n in range(batchsize): \n",
    "            model.train()\n",
    "\n",
    "            # forward\n",
    "            index_n = rand_n[n+batchsize*batch]\n",
    "            H0 = train_features[index_n,:,:]\n",
    "            index_0rd = (H0==0).flatten()\n",
    "            train_labels[index_n,index_0rd]=0##去除异常值\n",
    "            index_2rd = (train_labels[index_n]>2).flatten()\n",
    "            train_mask[index_n,index_2rd]=False ##去除太大的zhi\n",
    "            labels = train_labels[index_n,train_mask[index_n,:]]\n",
    "            if cuda== True:\n",
    "                H0=H0.cuda()\n",
    "                labels=labels.cuda()\n",
    "            N_t = labels.size(0)\n",
    "            y = model(H0) \n",
    "            index_0 = (labels) ==0 ###标签为0的索引\n",
    "            W_nodes = 10**(labels)  ##  weigtht for none zero label: W\n",
    "            W_nodes[index_0]=0.1  ## weight for zero label: W0\n",
    "            loss = loss_fcn( y[train_mask[index_n,:],:].flatten(),\n",
    "                            labels )  ###compute the loss for every (labeled) node\n",
    "\n",
    "            loss = loss*W_nodes \n",
    "            loss_w = loss.mean() ## average loss among all nodes\n",
    "            loss_m += loss.sum().item()\n",
    "            loss_w.backward()\n",
    "            N_ba +=N_t\n",
    "        optimizer1.step() \n",
    "        optimizer1.zero_grad()\n",
    "        N_nodes_train += N_ba           \n",
    "    for n in range(N_val):\n",
    "        model.eval()\n",
    "        index_0rd = (test_features[n]==0).flatten()\n",
    "        test_labels[n,index_0rd]=0##去除异常值\n",
    "        mask = (10**test_labels[n]-1)>0\n",
    "        index_2rd = (test_labels[n]>2).flatten()\n",
    "        test_mask[n,index_2rd]=False ##去除太大的zhi\n",
    "        mask = mask&test_mask[n]\n",
    "        test_F=test_features[n]\n",
    "        test_L=test_labels[n]\n",
    "        if cuda==True:\n",
    "            test_F=test_F.cuda()\n",
    "            test_L=test_L.cuda()\n",
    "        val_error0, N0 = evaluate0(model, test_F, test_L, mask, b_ms_error)#\n",
    "        val_error += val_error0\n",
    "        N_total += N0\n",
    "        \n",
    "    val_error/=N_total\n",
    "    if early_stop: \n",
    "        if stopper.step(-val_error, model, 'CNGAT_16_6_64.pt'):   \n",
    "            break\n",
    "    loss_m = loss_m/N_nodes_train\n",
    "    if epoch >= 3:\n",
    "        dur.append(time.time() - t0)\n",
    "    print(\"Epoch {:05d} | Time(s) {:.4f} | Loss {:.6f} |val_error{:.4f}\".\n",
    "              format(epoch, np.mean(dur), loss_m, val_error))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PPXXpytorch] *",
   "language": "python",
   "name": "conda-env-PPXXpytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
